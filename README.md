# Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy üöÄ

Implementation of *Anomaly Transformer*, from the paper [‚ÄúAnomaly Transformer: Time Series Anomaly Detection with Association Discrepancy‚Äù], spotlighted at **ICLR 2022** ([GitHub](https://github.com/thuml/Anomaly-Transformer), [arXiv](https://arxiv.org/abs/2110.02642)).

Unsupervised time-series anomaly detection using a novel **Association Discrepancy** criterion and **Anomaly-Attention** mechanism for enhanced distinguishability.

---

## üìå Key Contributions

- **Association Discrepancy**: A new anomaly scoring criterion based on contrast in self-attention patterns between normal and abnormal points.
- **Anomaly-Attention**: A transformer-based attention module geared toward detecting anomalies via pairwise associations.
- **Minimax strategy**: Optimized to amplify difference between normal and abnormal behaviors in association distributions.

---

## üß© Repository Structure

```
Anomaly-Transformer/
‚îú‚îÄ‚îÄ data_factory/    # data loading and processing utilities
‚îú‚îÄ‚îÄ model/           # model architecture definitions
‚îú‚îÄ‚îÄ scripts/         # training / evaluation scripts for each dataset
‚îú‚îÄ‚îÄ utils/           # helper functions
‚îú‚îÄ‚îÄ pics/            # illustrative or sample output images
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ main.py          # script entry point
‚îú‚îÄ‚îÄ solver.py        # training logic and loss implementation
‚îî‚îÄ‚îÄ results.txt      # stored experimental results
```

---

## ‚öôÔ∏è Installation

1. Install Python **>= 3.6** and PyTorch **>=‚ÄØ1.4.0**.
2. Clone this repository:

   ```bash
   git clone https://github.com/shashipreetham18/Anomaly-Transformer.git
   cd Anomaly-Transformer
   ```

3. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

---

## üìÇ Datasets

We support six popular benchmarks: **SMD**, **MSL**, **SMAP**, **PSM**, **SWaT**, **WADI**. All are preprocessed and hosted on Google Cloud. Note: you may need to apply separately for data access (e.g. for SWaT).

---

## ‚ñ∂Ô∏è Training & Evaluation

Use batch scripts in `scripts/`, for example:

```bash
bash ./scripts/SMD.sh
bash ./scripts/MSL.sh
bash ./scripts/SMAP.sh
bash ./scripts/PSM.sh
```

Alternatively, call the Python entry:

```bash
python main.py --dataset SMD --retrain
```

Scripts handle training and testing. Model outputs include anomaly detection metrics adjusted via point-adjustment strategy from Xu et al., 2018.

---

## üìä Results

Anomaly Transformer achieves **state-of-the-art performance** on all six benchmark datasets: service monitoring, space & earth datasets, and water treatment applications.

---
